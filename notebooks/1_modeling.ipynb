{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librerie e dataset\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, root_mean_squared_error, make_scorer\n",
    "import sklearn as sklearn\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna\n",
    "from sklearn.preprocessing import  TargetEncoder as tg\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import optuna.visualization as vis\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "\n",
    "df_original=pd.read_csv(r'path/to/your/dataset.csv')\n",
    "sklearn.set_config(transform_output='pandas')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e20f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtraggio colonne utili\n",
    "\n",
    "df_original = df_original[[\n",
    "    # Dati demografici e socioeconomici\n",
    "    'age', \n",
    "    'sex',\n",
    "    'marital_status',\n",
    "    'Race recode (White, Black, Other)',\n",
    "    'Race recode (with detailed Asian and Native Hawaiian other PI)',\n",
    "    'Origin recode NHIA (Hispanic, Non-Hisp)',\n",
    "    'median_household_income_adj_2023', 'rural_urban_continuum',\n",
    "    \n",
    "    # Caratteristiche del tumore\n",
    "    'primary_site', 'Schema ID (2018+)', 'ICD-O-3 Hist/behav',\n",
    "    'clinical_grade', 'diagnostic_confirmation',\n",
    "    'tumor_size_summary',\n",
    "    \n",
    "    # Stadio\n",
    "    'eod_t', 'eod_n', 'eod_m', 'eod_stage_group',\n",
    "    'eod_primary_tumor', 'eod_regional_nodes', 'eod_mets',\n",
    "    'n_sentinel_lymph_nodes',\n",
    "    \n",
    "    # Metastasi\n",
    "    'mets_at_bone', 'mets_at_brain', 'mets_at_liver', 'mets_at_lung', \n",
    "    'mets_at_dx_distand_ln', 'mets_at_dx_other',\n",
    "    \n",
    "    # Biomarcatori\n",
    "    'E_R_binary', 'pr_binary', 'her2_binary',\n",
    "    \n",
    "    # Trattamento\n",
    "    'days_from_diagnosis_to_treatment',\n",
    "    'rx_summ_surg_prim_site', 'rx_summ_scope_reg_ln_sur', 'rx_summ_surg_oth_reg_dis',\n",
    "    'rx_summ_surg_rad_seq', 'reason_no_surgery',\n",
    "    'radiation', 'chemo_yes_no', 'rx_summ_systemic_sur_seq',\n",
    "    \n",
    "    # Storia clinica \n",
    "    'first_malignant_tumor',\n",
    "    'n_benign_borderline_tumors', 'n_in_situ_malignant_tumors',\n",
    "    'survival_months',\n",
    "    \n",
    "    # Fonte \n",
    "    'report_source'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d23eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131974, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sampling dataframe\n",
    "df = df_original.sample(frac=1, random_state=42)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fed278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colonne numeriche e categoriche\n",
    "\n",
    "# Colonne categoriche\n",
    "cat_cols = [\n",
    "    # Dati demografici\n",
    "    'sex', \n",
    "    'marital_status',\n",
    "    'Race recode (White, Black, Other)',\n",
    "    'Race recode (with detailed Asian and Native Hawaiian other PI)',\n",
    "    'Origin recode NHIA (Hispanic, Non-Hisp)',\n",
    "    'rural_urban_continuum',\n",
    "    \n",
    "    # Caratteristiche del tumore\n",
    "    'primary_site',\n",
    "    'Schema ID (2018+)',\n",
    "    'ICD-O-3 Hist/behav',\n",
    "    'clinical_grade',\n",
    "    'diagnostic_confirmation',\n",
    "    'tumor_size_summary',\n",
    "    \n",
    "    # Stadiazione\n",
    "    'eod_t', 'eod_n', 'eod_m', 'eod_stage_group',\n",
    "    'eod_primary_tumor', 'eod_regional_nodes', 'eod_mets',\n",
    "    'n_sentinel_lymph_nodes',\n",
    "    \n",
    "    # Metastasi\n",
    "    'mets_at_bone', 'mets_at_brain', 'mets_at_liver', 'mets_at_lung',\n",
    "    'mets_at_dx_distand_ln', 'mets_at_dx_other',\n",
    "    \n",
    "    # Biomarcatori\n",
    "    'E_R_binary', 'pr_binary', 'her2_binary',\n",
    "    \n",
    "    # Trattamento\n",
    "    'rx_summ_surg_prim_site', 'rx_summ_scope_reg_ln_sur', 'rx_summ_surg_oth_reg_dis',\n",
    "    'rx_summ_surg_rad_seq', 'reason_no_surgery', 'radiation',\n",
    "    'chemo_yes_no', 'rx_summ_systemic_sur_seq',\n",
    "    \n",
    "    # Storia clinica\n",
    "    'first_malignant_tumor',\n",
    "    \n",
    "    # Fonte dei dati\n",
    "    'report_source'\n",
    "]\n",
    "\n",
    "# Colonne numeriche\n",
    "num_cols = [\n",
    "    #'age',\n",
    "    'days_from_diagnosis_to_treatment',\n",
    "    'median_household_income_adj_2023',\n",
    "    'n_in_situ_malignant_tumors',\n",
    "    'n_benign_borderline_tumors'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d3c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(df.drop(columns='survival_months'),df['survival_months'], test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce009167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd099581",
   "metadata": {},
   "source": [
    "# 1° regressione lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a812b5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.35276298286698"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder e pipeline\n",
    "encoding=ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            'onehot',\n",
    "            OneHotEncoder(sparse_output=False, min_frequency=5, handle_unknown='infrequent_if_exist'),\n",
    "            cat_cols\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    "    force_int_remainder_cols=False\n",
    ")\n",
    "\n",
    "pipe_rl=Pipeline(\n",
    "    [\n",
    "        ('encoder', encoding),\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rl.fit(x_train, y_train)\n",
    "y_test_pred=pipe_rl.predict(x_test)\n",
    "mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizzazione residui\n",
    "x_test['survival_months']=y_test\n",
    "x_test['predicted']=y_test_pred\n",
    "x_test['residuals']=x_test['survival_months']-x_test['predicted']\n",
    "\n",
    "\n",
    "fig = px.scatter(x_test, x=\"survival_months\", y=\"residuals\", hover_data=x_test.columns)\n",
    "\n",
    "fig.add_hline(y=0, line_color=\"red\", line_dash=\"dash\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef0cf8",
   "metadata": {},
   "source": [
    "# 2° random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.258560916284831\n"
     ]
    }
   ],
   "source": [
    "# primo tentativo\n",
    "regressor=RandomForestRegressor(n_estimators=20, max_depth=20,random_state=42)\n",
    "\n",
    "encoder=ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            'encoder',\n",
    "            OneHotEncoder(sparse_output=False, min_frequency=5, handle_unknown='infrequent_if_exist'),cat_cols\n",
    "        )  \n",
    "\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False,\n",
    "    force_int_remainder_cols=False\n",
    ")\n",
    "\n",
    "pipe_rf=Pipeline(\n",
    "    [\n",
    "        ('encoder', encoder),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', regressor)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf.fit(x_train, y_train)\n",
    "y_test_pred=pipe_rf.predict(x_test)\n",
    "print(mean_absolute_error(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search\n",
    "\n",
    "params = {\n",
    "    'rf__n_estimators': [50, 150, 300],  \n",
    "    'rf__criterion': ['squared_error', 'absolute_error'], \n",
    "    'encoder__encoder__min_frequency': [1, 7, 15],  \n",
    "    'rf__max_depth': [10, 18, 26], \n",
    "    'rf__min_samples_split': [2, 7],  \n",
    "    'rf__min_samples_leaf': [1, 3],  \n",
    "    'rf__max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid_search=GridSearchCV(\n",
    "    estimator=pipe_rf, \n",
    "    param_grid=params,\n",
    "    scoring= make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    n_jobs=-1,# quanti addestramenti in parallelo\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    refit=True, # riaddestra il modello sui parametri migliori senza split e validation\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "y_test_pred=grid_search.predict(x_test)\n",
    "print(mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ee269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search, devo testare troppi iperparametri\n",
    "\n",
    "params = {\n",
    "    'rf__n_estimators': [50, 150, 300],  \n",
    "    'rf__criterion': ['squared_error', 'absolute_error'],  # tolto 'friedman_mse'\n",
    "    'encoder__encoder__min_frequency': [1, 7, 15],  \n",
    "    'rf__max_depth': [10, 18, 26],  \n",
    "    'rf__min_samples_split': [2, 7],  \n",
    "    'rf__min_samples_leaf': [1, 3],  \n",
    "    'rf__max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid_search=RandomizedSearchCV(\n",
    "    estimator=pipe_rf, \n",
    "    n_iter=20, # bisogna dirgli quante iterazioni\n",
    "    param_distributions=params,  # cambia questo rispetto a gridsearch\n",
    "    scoring= make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    n_jobs=-1,\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    refit=True,\n",
    "    verbose=4\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred=grid_search.predict(x_test)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bf324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forse meglio usare optuna\n",
    "#study= optuna.create_study(storage=\"sqlite:///model_selection.db\", study_name=\"rf02_02\", direction=\"minimize\")\n",
    "study= optuna.load_study(storage=\"sqlite:///model_selection.db\", study_name=\"rf02_02\",)\n",
    "\n",
    "\n",
    "def objective_func(trial): # questa è una funzione obiettivo tipo\n",
    "    params={ # questa è una funzione obiettivo tipo\n",
    "    'rf__n_estimators': trial.suggest_categorical(\"rf__n_estimators\",  [150,250,400]),\n",
    "    'encoder__encoder__min_frequency' : trial.suggest_categorical('encoder__encoder__min_frequency',  [ 7, 15]),\n",
    "    'rf__max_depth' : trial.suggest_categorical(\"rf__max_depth\", [10, 18, 26]),\n",
    "    'rf__min_samples_split' : trial.suggest_categorical('rf__min_samples_split', [2, 7]),\n",
    "    'rf__min_samples_leaf' : trial.suggest_categorical('rf__min_samples_leaf', [1, 3]),\n",
    "    }\n",
    "\n",
    "    pipe_rf.set_params(**params)\n",
    "    #usiamo cross validate. vedi documentazione\n",
    "\n",
    "    cross_v=cross_validate(\n",
    "        pipe_rf,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        scoring=make_scorer(mean_absolute_error,greater_is_better=False),\n",
    "        cv=KFold(shuffle=True, random_state=42)\n",
    "        )\n",
    "    return abs(sum(cross_v['test_score'])/len(cross_v['test_score']))\n",
    "\n",
    "n_trials = 10\n",
    "with tqdm(total=n_trials) as pbar:\n",
    "    def tqdm_callback(study, trial):\n",
    "        pbar.update(1)\n",
    "    \n",
    "    study.optimize(objective_func, n_trials=n_trials, callbacks=[tqdm_callback])\n",
    "\n",
    "best_params = study.best_params\n",
    "pipe_rf.set_params(**best_params)\n",
    "pipe_rf.fit(x_train, y_train)\n",
    "y_test_pred = pipe_rf.predict(x_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "study.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbafbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizzazione studio\n",
    "study= optuna.load_study(storage=\"sqlite:///model_selection.db\", study_name=\"rf02_02\",)\n",
    "vis.plot_optimization_history(study).show()\n",
    "vis.plot_param_importances(study).show()\n",
    "vis.plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511498f",
   "metadata": {},
   "source": [
    "# 3° XGBoost\n",
    "\n",
    "Selgo di usare xgboost, non perché gli altri algoritmi non si sono mostrati validi, ma perché usando dmatrix è più veloce. \n",
    "\n",
    "Ha appoggio GPU, testato ma non implementato in questo notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431571ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#faccio questo tipo di model selection: valuto diversi encoding e diversi iperparametri di xgboost\n",
    "study = optuna.create_study(storage=\"sqlite:///model_selection.db\", study_name=\"xgb_opt_03_01\", direction=\"minimize\")\n",
    "\n",
    "def objective(trial):\n",
    "    model_choice = trial.suggest_categorical(\"model_choice\", [\"onehot\", 'binary', 'target'])\n",
    "\n",
    "    if model_choice == \"onehot\":\n",
    "        min_freq = trial.suggest_int(\"encoder__encoder__min_frequency\", 1,40)\n",
    "        encoder = OneHotEncoder(sparse_output=False, \n",
    "                                handle_unknown=\"infrequent_if_exist\", \n",
    "                                min_frequency= min_freq)\n",
    "\n",
    "        n_estimators=trial.suggest_categorical(\"xgb__n_estimators\", [400,500,600,700,800])\n",
    "        max_depth= trial.suggest_int(\"xgb__max_depth\", 5, 25)\n",
    "        learning_rate= trial.suggest_float(\"xgb__learning_rate\", 0.01, 0.08)\n",
    "        subsample= trial.suggest_float(\"xgb__subsample\", 0.6, 1.0)\n",
    "        colsample_bytree= trial.suggest_float(\"xgb__colsample_bytree\", 0.4, 0.8)\n",
    "        min_child_weight= trial.suggest_int(\"xgb__min_child_weight\", 3, 10)\n",
    "        objective= trial.suggest_categorical(\"xgb__objective\",['reg:squarederror', 'reg:absoluteerror'] )\n",
    "\n",
    "    elif model_choice == \"target\":\n",
    "        smoothing=trial.suggest_categorical('encoder__encoder__smoothing',[0.1, 0.3, 1, 3, 10, 30, 100])\n",
    "        encoder = tg(target_type=\"continuous\", \n",
    "                                random_state=42, \n",
    "                                #min_samples_leaf=min_samples_leaf,\n",
    "                                smooth=smoothing\n",
    "                                )\n",
    "\n",
    "        n_estimators=trial.suggest_categorical(\"xgb__n_estimators\", [400,500,600,700,800])\n",
    "        max_depth= trial.suggest_int(\"xgb__max_depth\", 5, 25)\n",
    "        learning_rate= trial.suggest_float(\"xgb__learning_rate\", 0.01, 0.08)\n",
    "        subsample= trial.suggest_float(\"xgb__subsample\", 0.6, 1.0)\n",
    "        colsample_bytree= trial.suggest_float(\"xgb__colsample_bytree\", 0.4, 0.8)\n",
    "        min_child_weight= trial.suggest_int(\"xgb__min_child_weight\", 3, 10)\n",
    "        objective= trial.suggest_categorical(\"xgb__objective\",['reg:squarederror', 'reg:absoluteerror'] )\n",
    "\n",
    "    else:  \n",
    "        encoder = BinaryEncoder(cols=cat_cols, return_df=True)\n",
    "        n_estimators=trial.suggest_categorical(\"xgb__n_estimators\", [400,500,600,700,800])\n",
    "        max_depth= trial.suggest_int(\"xgb__max_depth\", 5, 25)\n",
    "        learning_rate= trial.suggest_float(\"xgb__learning_rate\", 0.01, 0.08)\n",
    "        subsample= trial.suggest_float(\"xgb__subsample\", 0.6, 1.0)\n",
    "        colsample_bytree= trial.suggest_float(\"xgb__colsample_bytree\", 0.4, 0.8)\n",
    "        min_child_weight= trial.suggest_int(\"xgb__min_child_weight\", 3, 10)\n",
    "        objective= trial.suggest_categorical(\"xgb__objective\",['reg:squarederror', 'reg:absoluteerror'] )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=\n",
    "        [\n",
    "            ('cat',encoder, cat_cols),\n",
    "            ('num', StandardScaler(), num_cols)\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False,\n",
    "        force_int_remainder_cols=False\n",
    "        )\n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        subsample=subsample,#frazione di campioni usata per costruire ogni albero (stocasticità). Riduce overfitting\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        min_child_weight=min_child_weight, #soglia minima sulla somma dei pesi (cioè degli \"hessian\", nel contesto XGBoost) nei nodi figli. Valori alti impediscono la crescita di nodi con pochi dati, aumentando il bias.\n",
    "        objective=objective,\n",
    "        learning_rate=learning_rate, \n",
    "        random_state=42,\n",
    "        \n",
    "        tree_method='hist',  # più veloce\n",
    "        n_jobs=-1\n",
    "        )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"encoder\", preprocessor),\n",
    "        (\"regressor\", xgb)\n",
    "    ])\n",
    "\n",
    "    cross_v = cross_validate(\n",
    "        pipe,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        cv=KFold(shuffle=True, random_state=42)\n",
    "    )\n",
    "\n",
    "    return abs(cross_v['test_score'].mean())\n",
    "\n",
    "# Lancio dell’ottimizzazione\n",
    "n_trials = 2\n",
    "with tqdm(total=n_trials) as pbar:\n",
    "    def tqdm_callback(study, trial):\n",
    "        pbar.update(1)\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[tqdm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizzazione risultati\n",
    "study = optuna.load_study(storage=\"sqlite:///model_selection2.db\", study_name=\"xgb_opt_01_01\")\n",
    "\n",
    "vis.plot_optimization_history(study).show()\n",
    "vis.plot_param_importances(study).show()\n",
    "vis.plot_parallel_coordinate(study).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d044a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection con solo target encoding\n",
    "#study = optuna.create_study(storage=\"sqlite:///model_selection.db\", study_name=\"xgb_opt_04_4\", direction=\"minimize\")\n",
    "study=optuna.load_study(storage=\"sqlite:///model_selection.db\", study_name=\"xgb_opt_04_4\")\n",
    "def objective(trial):\n",
    "    #min_samples_leaf= trial.suggest_int(\"encoder__encoder__min_samples_leaf\", 1,15)\n",
    "    smoothing=trial.suggest_categorical('encoder__encoder__smoothing',[3,15])\n",
    "    encoder = tg(target_type=\"continuous\", \n",
    "                            random_state=42, \n",
    "                            #min_samples_leaf=min_samples_leaf,\n",
    "                            smooth=smoothing\n",
    "                            )\n",
    "\n",
    "    n_estimators=trial.suggest_categorical(\"xgb__n_estimators\", [1300,1800,2000,2500,3000])\n",
    "    max_depth= trial.suggest_int(\"xgb__max_depth\", 6, 15)\n",
    "    learning_rate= trial.suggest_float(\"xgb__learning_rate\", 0.01,0.03)\n",
    "    colsample_bytree= trial.suggest_float(\"xgb__colsample_bytree\", 0.6, 0.75)\n",
    "    min_child_weight= trial.suggest_int(\"xgb__min_child_weight\", 6, 7)\n",
    "\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=\n",
    "        [\n",
    "            ('cat',encoder, cat_cols),\n",
    "            ('num', StandardScaler(), num_cols)\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False,\n",
    "        force_int_remainder_cols=False\n",
    "        )\n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        subsample=0.6005480544522415,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        min_child_weight=min_child_weight,\n",
    "        objective='reg:absoluteerror',\n",
    "        learning_rate=learning_rate, \n",
    "        random_state=42,\n",
    "        \n",
    "        tree_method='hist',  # più veloce\n",
    "        n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (\"encoder\", preprocessor),\n",
    "        (\"xgb\", xgb)\n",
    "    ])\n",
    "\n",
    "    cross_v = cross_validate(\n",
    "        pipe,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        cv=KFold(shuffle=True, random_state=42)\n",
    "    )\n",
    "\n",
    "    return abs(cross_v['test_score'].mean())\n",
    "\n",
    "n_trials =200\n",
    "with tqdm(total=n_trials) as pbar:\n",
    "    def tqdm_callback(study, trial):\n",
    "        pbar.update(1)\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[tqdm_callback])\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a seguito di diversi studi optuna, tentativi naive e manuali, qui sotto modello con quelli che sembrano essere gli iperparametri migliori\n",
    "encoder=tg(target_type='continuous', random_state=42,smooth=3 )\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=\n",
    "    [\n",
    "        ('cat',encoder, cat_cols),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    "    force_int_remainder_cols=False\n",
    "    )\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=3000,\n",
    "    min_child_weight= 6,\n",
    "    max_depth= 7,\n",
    "    learning_rate=0.01278,\n",
    "    colsample_bytree =0.65884,\n",
    "    objective='reg:absoluteerror',\n",
    "    random_state=42,\n",
    "    tree_method='hist',  # più veloce\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"encoder\", preprocessor),\n",
    "    (\"xgb\", xgb)\n",
    "])\n",
    "\n",
    "pipe_xgb.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred=pipe_xgb.predict(x_test)\n",
    "\n",
    "mean_absolute_error(y_test, y_test_pred)\n",
    "#5.764026641845703\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148559d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisi dei residui\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'actual_y': y_test,\n",
    "    'predicted_y': y_test_pred,\n",
    "    'residuals': y_test - y_test_pred\n",
    "})\n",
    "\n",
    "fig = px.scatter(results, x=\"actual_y\", y=\"residuals\", hover_data=results.columns)\n",
    "fig.add_hline(y=0, line_color=\"red\", line_dash=\"dash\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fde8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.48773193359375"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mae sul train set\n",
    "y_test_pred=pipe_xgb.predict(x_train)\n",
    "mean_absolute_error(y_train, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c744bec",
   "metadata": {},
   "source": [
    "# 4° Provo a correggere le previsioni con un modello per prevedere i residui.\n",
    "\n",
    "L'obiettivo è prevedere l'errore e sottrarlo alla previsione vera e propria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1082001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previsioni, calcolo residui, inizializzazione nuovo dataset, train test split\n",
    "\n",
    "y_train_pred=pipe_xgb.predict(x_train)\n",
    "train_residui=y_train-y_train_pred\n",
    "df2=x_train\n",
    "df2['residuals']=train_residui\n",
    "df2 = df2.sample(frac=1, random_state=42)\n",
    "res_x_train,res_x_test, res_y_train, res_y_test=train_test_split(df2.drop(columns='residuals'),df2['residuals'], test_size=0.2, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdcd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso un modello simile al precedente e faccio uno studio con optuna per cercare i migliori iperparametri\n",
    "\n",
    "study = optuna.create_study(storage=\"sqlite:///model_selection.db\", study_name=\"xgb_opt_05_2\", direction=\"minimize\")\n",
    "#study=optuna.load_study(storage=\"sqlite:///model_selection.db\", study_name=\"xgb_opt_04_4\")\n",
    "def objective(trial):\n",
    "    #min_samples_leaf= trial.suggest_int(\"encoder__encoder__min_samples_leaf\", 1,15)\n",
    "    smoothing=trial.suggest_categorical('encoder__smoothing',[3,5,15])\n",
    "    encoder = tg(target_type=\"continuous\", \n",
    "                            random_state=42, \n",
    "                            #min_samples_leaf=min_samples_leaf,\n",
    "                            smooth=smoothing\n",
    "                            )\n",
    "\n",
    "    n_estimators=trial.suggest_categorical(\"xgb__n_estimators\", [1300,1800,2000,2500,3000])\n",
    "    max_depth= trial.suggest_int(\"xgb__max_depth\", 6, 15)\n",
    "    learning_rate= trial.suggest_float(\"xgb__learning_rate\", 0.01,0.03)\n",
    "    colsample_bytree= trial.suggest_float(\"xgb__colsample_bytree\", 0.2, 0.75)\n",
    "    min_child_weight= trial.suggest_int(\"xgb__min_child_weight\", 4, 8)\n",
    "    subsample= trial.suggest_float(\"xgb__subsample\", 0.6, 1.0)\n",
    "    objective=trial.suggest_categorical('xgb__objective',['reg:absoluteerror','reg:squarederror'])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=\n",
    "        [\n",
    "            ('cat',encoder, cat_cols),\n",
    "            ('num', StandardScaler(), num_cols)\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False,\n",
    "        force_int_remainder_cols=False\n",
    "        )\n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        min_child_weight=min_child_weight,\n",
    "        objective=objective,\n",
    "        learning_rate=learning_rate, \n",
    "        random_state=42,\n",
    "        \n",
    "        tree_method='hist',  # più veloce\n",
    "        n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    pipe2 = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"xgb\", xgb)\n",
    "    ])\n",
    "\n",
    "    cross_v = cross_validate(\n",
    "        pipe2,\n",
    "        res_x_train,\n",
    "        res_y_train,\n",
    "        scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        cv=KFold(shuffle=True, random_state=42)\n",
    "    )\n",
    "\n",
    "    return abs(cross_v['test_score'].mean())\n",
    "\n",
    "n_trials =200\n",
    "with tqdm(total=n_trials) as pbar:\n",
    "    def tqdm_callback(study, trial):\n",
    "        pbar.update(1)\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[tqdm_callback])\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizzazione risultati studio\n",
    "study = optuna.load_study(storage=\"sqlite:///model_selection.db\", study_name=\"xgb_opt_05_2\")\n",
    "vis.plot_optimization_history(study).show()\n",
    "vis.plot_param_importances(study).show()\n",
    "vis.plot_parallel_coordinate(study).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce06c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondo modello completo e fit con i migliori iperparametri \n",
    "\n",
    "# encoder e pipeline\n",
    "y_train_pred=pipe_xgb.predict(x_train)\n",
    "train_residui=y_train-y_train_pred#calcolo residui train\n",
    "encoder=tg(target_type='continuous', random_state=42,smooth=5 )\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=\n",
    "    [\n",
    "        ('cat',encoder, cat_cols),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    "    force_int_remainder_cols=False\n",
    "    )\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=2500,\n",
    "    min_child_weight= 6,\n",
    "    max_depth= 7,\n",
    "    learning_rate=0.012078,\n",
    "    colsample_bytree =0.65884,\n",
    "    objective='reg:absoluteerror',\n",
    "    random_state=42,\n",
    "    tree_method='hist',  # più veloce\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    (\"encoder\", preprocessor),\n",
    "    (\"xgb\", xgb)\n",
    "])\n",
    "\n",
    "\n",
    "pipe2.fit(res_x_train, res_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd9d948b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.749392509460449"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcolo migliori previsioni e valutazione con MAE\n",
    "\n",
    "y_test_pred=pipe_xgb.predict(x_test) # valori pred test y\n",
    "\n",
    "y_residui_predetti=pipe2.predict(x_test)\n",
    "test_final=y_test_pred+y_residui_predetti\n",
    "mean_absolute_error(y_test, test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00c1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.422630786895752"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mae sul train set\n",
    "\n",
    "y_train_pred=pipe_xgb.predict(x_train) # valori pred test y\n",
    "test_residui=y_train - y_train_pred# valori residui differenza tra y_test e i predetti\n",
    "y_residui_predetti=pipe2.predict(x_train)\n",
    "final=y_train_pred+y_residui_predetti\n",
    "mean_absolute_error(y_train, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc7b643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1274012720572175"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provo ad usare un regressore lineare come secondo modello \n",
    "encoder=tg(target_type='continuous', random_state=42,smooth=5 )\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=\n",
    "    [\n",
    "        ('cat',encoder, cat_cols),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    "    force_int_remainder_cols=False\n",
    "    )\n",
    "\n",
    "\n",
    "pipe_rl2=Pipeline(\n",
    "    [\n",
    "       \n",
    "        ('preprocessor', preprocessor),\n",
    "        ('linreg', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rl2.fit(res_x_train, res_y_train)\n",
    "\n",
    "y_test_pred=pipe_xgb.predict(x_test) # valori pred test y\n",
    "\n",
    "piperl2_residui_predetti=pipe_rl2.predict(x_test)\n",
    "test_final_lr=y_test_pred+piperl2_residui_predetti\n",
    "mean_absolute_error(y_test, test_final_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f21827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafici dei residui prima e dopo la correzione con secondo modello\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'actual_y': y_test,\n",
    "    'predicted_y': test_final,\n",
    "    'residuals': y_test - test_final\n",
    "})\n",
    "\n",
    "fig = px.scatter(results, x=\"actual_y\", y=\"residuals\", hover_data=results.columns)\n",
    "fig.add_hline(y=0, line_color=\"red\", line_dash=\"dash\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico residui veri e residui predetti\n",
    "\n",
    "df_residui = pd.DataFrame({\n",
    "    \"residui_veri\": test_residui,\n",
    "    \"residui_predetti\": y_residui_predetti\n",
    "})\n",
    "\n",
    "fig = px.scatter(df_residui, x=\"residui_veri\", y=\"residui_predetti\",\n",
    "                 title=\"Residui veri vs residui predetti dal secondo modello\",\n",
    "                 labels={\"residui_veri\": \"Residui veri\", \"residui_predetti\": \"Residui predetti\"})\n",
    "\n",
    "fig.add_hline(y=0, line_color=\"red\", line_dash=\"dash\")\n",
    "fig.add_vline(x=0, line_color=\"red\", line_dash=\"dash\")\n",
    "\n",
    "#fig.update_layout(width=700, height=500)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00083a46",
   "metadata": {},
   "source": [
    "# naive features engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico importanza features\n",
    "\n",
    "booster = pipe_xgb.named_steps['xgb']\n",
    "feature_names = pipe_xgb.named_steps['encoder'].get_feature_names_out() \n",
    "importances = booster.feature_importances_\n",
    "\n",
    "df_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "df_sort = df_importance.sort_values(by='importance', ascending=False).head(10)\n",
    "\n",
    "# Grafico interattivo a barre\n",
    "fig = px.bar(df_sort, x='importance', y='feature', orientation='h', title=\"Top 10 Feature Importances\")\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()\n",
    "\n",
    "print(df_sort)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
